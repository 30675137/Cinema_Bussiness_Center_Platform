---
name: e2e-test-executor
description: |
  Execute end-to-end integration tests based on test case documents generated by e2e-test-writer skill.
  Automatically generates test code, runs tests, validates data (API/database/BOM inventory), and produces
  comprehensive test reports. Use when: (1) User provides a test case document (e2e-test-case.md) and wants
  to execute tests, (2) User asks to "run tests", "execute test cases", "validate the implementation", or
  "generate test report", (3) Need to verify order flow, BOM inventory deduction, or database state changes,
  (4) Completing implementation and need to validate against test cases.
---

# E2E Test Executor

Execute integration tests from test case documents, validate implementation, and generate test reports.

## Overview

This skill reads test case documents (generated by e2e-test-writer), generates executable test code, runs tests against the actual system, and produces detailed test reports with pass/fail statistics and defect tracking.

## Workflow

### 1. Locate Test Case Document

Find the test case document (usually `specs/<specId>/e2e-test-case.md`):

```bash
# If user provides path
cat specs/O003-beverage-order/e2e-test-case.md

# If not provided, search for it
find specs -name "e2e-test-case.md" -o -name "*test*.md"
```

### 2. Parse Test Cases

Use `scripts/parse_test_doc.py` to extract structured test case data:

```python
python3 scripts/parse_test_doc.py specs/O003-beverage-order/e2e-test-case.md --output test-cases.json
```

Output: JSON file containing:
- Test case IDs
- Test steps
- Expected results
- Data validation checks
- Pre/post conditions

### 3. Generate Test Code

Based on the test type, generate appropriate test code:

**For API Tests** (Backend endpoints):
```bash
python3 scripts/generate_api_test.py test-cases.json --framework jest --output tests/e2e/
```

**For UI Tests** (C端/B端):
```bash
python3 scripts/generate_ui_test.py test-cases.json --framework playwright --output tests/e2e/
```

See [references/test-frameworks.md](references/test-frameworks.md) for framework selection guidance.

### 4. Execute Tests

Run generated tests and collect results:

```bash
python3 scripts/execute_tests.py tests/e2e/ --env development --report report.json
```

Options:
- `--env`: Test environment (development/test/staging)
- `--report`: Output file for test results
- `--parallel`: Run tests in parallel
- `--verbose`: Show detailed logs

### 5. Generate Test Report

Create a comprehensive Markdown report:

```bash
python3 scripts/generate_report.py report.json --template assets/test-report-template.md --output test-report.md
```

Report includes:
- Test execution statistics (pass/fail/blocked)
- Defect list with severity
- Screenshots/logs for failures
- Updated test case document with actual results filled in

### 6. Update Test Case Document

Automatically update the original test case document with actual results:

```python
python3 scripts/update_test_doc.py specs/O003-beverage-order/e2e-test-case.md report.json
```

This fills in:
- "实际结果" columns
- "通过状态" checkboxes
- Defect records section

## Test Types Supported

### API Tests (Backend)
- REST API endpoint validation
- Request/response verification
- Database state checks
- BOM inventory deduction validation
- Error handling verification

Framework: Jest + Supertest or REST Assured (Java)

### UI Tests (Frontend)
- **C端 (Taro小程序/H5)**: User flow simulation
- **B端 (React+AntD)**: Admin operations
- Element interactions, form submissions
- Visual regression (screenshots)

Framework: Playwright

### Database Validation
- Query database after operations
- Verify data integrity
- Check state transitions
- Validate timestamps and relationships

Method: Direct SQL queries via Supabase client or JDBC

### BOM Inventory Validation
- Call P003/P004 inventory APIs
- Verify stock deductions
- Check adjustment logs
- Validate inventory transactions

Method: API calls to inventory management endpoints

## Assertion Patterns

See [references/assertion-patterns.md](references/assertion-patterns.md) for common assertion patterns:
- Order status transitions
- BOM deduction calculations
- Timestamp ordering
- Error message validation

## Test Data Management

See [references/test-data-setup.md](references/test-data-setup.md) for:
- Setting up test data before tests
- Cleaning up after tests
- Managing test user accounts
- Handling concurrent test execution

## Resources

### scripts/
- `parse_test_doc.py` - Parse test case documents
- `generate_api_test.py` - Generate API test code
- `generate_ui_test.py` - Generate UI test code
- `execute_tests.py` - Run tests and collect results
- `generate_report.py` - Create test reports
- `update_test_doc.py` - Update test case doc with results

### references/
- `test-frameworks.md` - Framework selection guide
- `assertion-patterns.md` - Common assertion patterns
- `test-data-setup.md` - Test data preparation

### assets/
- `test-template.spec.ts` - Playwright test template
- `api-test-template.test.ts` - API test template
- `test-report-template.md` - Test report template

## Example Usage

```bash
# Full workflow
python3 scripts/parse_test_doc.py specs/O003-beverage-order/e2e-test-case.md --output test-cases.json
python3 scripts/generate_api_test.py test-cases.json --framework jest --output tests/e2e/
python3 scripts/generate_ui_test.py test-cases.json --framework playwright --output tests/e2e/
python3 scripts/execute_tests.py tests/e2e/ --env development --report report.json
python3 scripts/generate_report.py report.json --output test-report.md
python3 scripts/update_test_doc.py specs/O003-beverage-order/e2e-test-case.md report.json
```

## Tips

- **Start with API tests**: Faster execution, easier debugging
- **Mock external dependencies**: Use MSW for API mocking
- **Run tests in CI/CD**: Integrate with GitHub Actions
- **Parallel execution**: Use `--parallel` for faster runs
- **Headless mode**: Playwright runs headless by default
- **Debug mode**: Use `--headed` and `--debug` for Playwright debugging
